{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_cols = ['date', 'gameId', 'home_teamID', 'visitor_teamID']\n",
    "\n",
    "\n",
    "currDir = os.getcwd()\n",
    "\n",
    "threeAvgDF = pd.read_csv(currDir+'\\\\data\\\\threeAvgsWeighted.csv').drop(ignore_cols,axis=1)\n",
    "\n",
    "print('Total (Rows, Columns):', threeAvgDF.shape)\n",
    "x = threeAvgDF[threeAvgDF.columns[:-1]]\n",
    "y = list(threeAvgDF['hWin'])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.20,random_state=123,shuffle=True)\n",
    "\n",
    "print('Training (Rows, Columns):', x_train.shape) # 80% of the data to be trained on\n",
    "print('Testing (Rows, Columns):', x_test.shape) # 20% of the data to be tested on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Distribution of training data\\n\\nHome Wins:', y_train.count(1), '| Away Wins:',y_train.count(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def shuffleTeams(x_df, y_df, percentToShuffle):\n",
    "\n",
    "    toShuffle = random.sample(population=range(len(x_df)), k=math.floor(percentToShuffle*len(x_df)))\n",
    "    \n",
    "    homeCols = x_df.columns[2:25]\n",
    "    visitorCols = x_df.columns[25:-1]\n",
    "    \n",
    "    data = {}\n",
    "    ret_y = []\n",
    "    \n",
    "    for col in x_df.columns:\n",
    "        data.update({col : []})\n",
    "    \n",
    "    dataLen = len(list(data.keys()))-1\n",
    "    visitorStart = 22\n",
    "    \n",
    "    z=0\n",
    "    for i, row in x_df.iterrows():\n",
    "        \n",
    "        if i in toShuffle:\n",
    "            columns = list(x_df.columns)\n",
    "            \n",
    "            for iCol in range(22):\n",
    "                homeCol = columns[iCol]\n",
    "                visitorCol = columns[visitorStart+iCol]\n",
    "                \n",
    "                data[homeCol].append(row[visitorCol])\n",
    "                data[visitorCol].append(row[homeCol])\n",
    "            if y_df[z]:\n",
    "                ret_y.append(0)\n",
    "            else:\n",
    "                ret_y.append(1)\n",
    "        else:\n",
    "            for col in x_df.columns:\n",
    "                data[col].append(row[col])\n",
    "            ret_y.append(y_df[z])\n",
    "        z+=1\n",
    "        \n",
    "    retVal = pd.DataFrame(data)\n",
    "        \n",
    "    return retVal, ret_y\n",
    "\n",
    "homeWins = y_train.count(1)\n",
    "awayWins = y_train.count(0)\n",
    "\n",
    "\n",
    "while homeWins/(homeWins+awayWins) < 0.52 or homeWins/(homeWins+awayWins) > 0.55:\n",
    "    \n",
    "    print(f'Home Wins: {homeWins}, Away Wins: {awayWins}')\n",
    "    clear_output(wait=True)\n",
    "    x_train, y_train = shuffleTeams(x_train, y_train, 0.1)\n",
    "    \n",
    "    homeWins = y_train.count(1)\n",
    "    awayWins = y_train.count(0)\n",
    "\n",
    "\n",
    "print(f'Home Wins: {homeWins}, Away Wins: {awayWins}')\n",
    "print(f'Percentage of Home Wins: {homeWins/(homeWins+awayWins)}')\n",
    "print(f'Shape: {x_train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize Input\n",
    "This aligns the data to be in the format of mean=0 and standard deviation=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameters\n",
    "Unfortunately, these are arbitrary for now, they can be optimized later with more work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 150\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 2e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "\n",
    "class trainData(Dataset):\n",
    "    \n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "    \n",
    "train_data = trainData(torch.FloatTensor(x_train), torch.FloatTensor(y_train))\n",
    "\n",
    "# Test data\n",
    "\n",
    "class testData(Dataset):\n",
    "    \n",
    "    def __init__(self, x_data):\n",
    "        self.x_data = x_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "    \n",
    "test_data = testData(torch.FloatTensor(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Neural Net Architecture\n",
    "This Neural Network has one hidden layer with 128 nodes, and produces noise in 30% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class breakingBasketball(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(breakingBasketball, self).__init__()\n",
    "        \n",
    "        # Number of input features is 44\n",
    "        self.layer_1 = nn.Linear(44, 88)\n",
    "        self.layer_out = nn.Linear(88, 1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(88)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = breakingBasketball()\n",
    "model.to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "    \n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossTracker = []\n",
    "accTracker = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    for x_batch, y_batch in train_loader:\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(x_batch)\n",
    "\n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    lossTracker.append(epoch_loss/len(train_loader))\n",
    "    accTracker.append(epoch_acc/len(train_loader))\n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lossTracker, linewidth=1, c='dodgerblue')\n",
    "plt.xlabel('Epoch Number', fontsize=12)\n",
    "plt.ylabel('Loss Score', fontsize=12)\n",
    "plt.savefig('LossHomeAdv.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(accTracker, linewidth=1, c='dodgerblue')\n",
    "plt.xlabel('Epoch Number', fontsize=12)\n",
    "plt.ylabel('Accuracy (%)', fontsize=12)\n",
    "plt.savefig('AccHomeAdv.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for x_batch in test_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_test_pred = model(x_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_list.append(round(y_test_pred.numpy()[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visitorPredWins = y_pred_list.count(0)\n",
    "homePredWins = y_pred_list.count(1)\n",
    "\n",
    "labels = 'Home Predicted Wins', 'Visitor Predicted Wins'\n",
    "sizes = [homePredWins, visitorPredWins]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(x=labels, height=sizes, color='dodgerblue')\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.ylim(0,700)\n",
    "plt.savefig('predHomeAdvantageDistribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(y_test, y_pred_list)\n",
    "true_negatives, false_positives, false_negatives, true_positives = matrix[0][0], matrix[0][1], matrix[1][0], matrix[1][1]\n",
    "print('True Negatives:', true_negatives)\n",
    "print('False Positives:', false_positives)\n",
    "print('False Negatives:', false_negatives)\n",
    "print('True Positives:', true_positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = round(100*(true_negatives+true_positives)/(true_positives+true_negatives+false_positives+false_negatives),3)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 'Correctly Predicted', 'Incorrectly Predicted'\n",
    "sizes = [test_acc/100, 1-(test_acc/100)]\n",
    "explode = (0.05, 0.05)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[10,6])\n",
    "ax.pie(sizes, explode=explode, autopct='%2.2f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax.axis('equal')\n",
    "\n",
    "plt.savefig('homeBiasPieChart.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testTracker = [test_acc for x in range(len(accTracker))]\n",
    "plt.plot(accTracker, linewidth=1, c='dodgerblue')\n",
    "plt.plot(testTracker, linewidth=1.5, c='red')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'bestModelNoHomeTeamAdv.pkl'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currDir = os.getcwd()\n",
    "teamsDF = pd.read_csv(currDir+'\\\\data\\\\teams.csv')\n",
    "\n",
    "teamsDict = {}\n",
    "for i in range(len(teamsDF)):\n",
    "    teamsDict.update({teamsDF['code'][i] : teamsDF['name'][i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictGame(model, gameStats, hasOutcome):\n",
    "    team1, team2 = gameStats['home_teamID'], gameStats['visitor_teamID']\n",
    "    hTeam, vTeam = teamsDict[team1], teamsDict[team2]\n",
    "    \n",
    "    ignore_cols = ['date', 'gameId', 'home_teamID', 'visitor_teamID']\n",
    "    if hasOutcome:\n",
    "        outcome = gameStats[-1]\n",
    "        ignore_cols.append('hWin')\n",
    "        \n",
    "    gameStats = gameStats.drop(ignore_cols)\n",
    "    gameStats = torch.FloatTensor([gameStats])\n",
    "    \n",
    "    y_test_pred = model(gameStats)\n",
    "    y_test_pred = torch.sigmoid(y_test_pred).item()\n",
    "    prediction = round(y_test_pred)\n",
    "    \n",
    "    if prediction:\n",
    "        print(hTeam, 'will beat', vTeam, '\\n')\n",
    "        if hasOutcome and outcome == prediction:\n",
    "            #print('And the model was right!\\n')\n",
    "            return 1\n",
    "        else:\n",
    "            #print('But the model was wrong\\n')\n",
    "            return 0\n",
    "    else:\n",
    "        print(vTeam, 'will beat', hTeam, '\\n')\n",
    "        if hasOutcome and outcome == prediction:\n",
    "            #print('And the model was right!\\n')\n",
    "            return 1\n",
    "        else:\n",
    "            #print('But the model was wrong\\n')\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currDir = os.getcwd()\n",
    "gamesDF = pd.read_csv(currDir+'\\\\data\\\\threeAvgsWeighted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homeAdv = int(input('Type 1 if you want home team advantage, 0 if not: '))\n",
    "\n",
    "bestModel = 'bestModelNoHomeTeamAdv.pkl'\n",
    "if homeAdv:\n",
    "    bestModel = 'bestModelHomeTeamAdv.pkl'\n",
    "    \n",
    "loaded_model = pickle.load(open(bestModel, 'rb'))\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twenty15 = np.logical_and(gamesDF['gameId'] >= 41500400, gamesDF['gameId'] < 41600000)\n",
    "twenty16 = np.logical_and(gamesDF['gameId'] >= 41600400, gamesDF['gameId'] < 41700000)\n",
    "fifteenSixteen = np.logical_or(twenty15, twenty16)\n",
    "\n",
    "twenty17 = np.logical_and(gamesDF['gameId'] >= 41700400, gamesDF['gameId'] < 41800000)\n",
    "twenty18 = np.logical_and(gamesDF['gameId'] >= 41800400, gamesDF['gameId'] < 41900000)\n",
    "seventeenEighteen = np.logical_or(twenty17, twenty18)\n",
    "\n",
    "firstFour = np.logical_or(fifteenSixteen, seventeenEighteen)\n",
    "\n",
    "playoffGames = np.logical_or(firstFour, gamesDF['gameId'] >= 41900400)\n",
    "\n",
    "finals = gamesDF[playoffGames]\n",
    "\n",
    "predictYear = []\n",
    "for i in range(len(finals)):\n",
    "    thisYear = int(finals.iloc[i]['date']/10000)\n",
    "    if thisYear not in predictYear:\n",
    "        predictYear.append(thisYear)\n",
    "        print(thisYear, 'finals\\n')\n",
    "    predictGame(loaded_model, finals.iloc[i], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
